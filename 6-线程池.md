#   0、Java并发编程三个重要特性

# [#](#原子性) 原子性

一次操作或者多次操作，要么所有的操作全部都得到执行**并且不会受到任何因素的干扰而中**断，要么都不执行。

## 1、为什么会存在原子性问题？

- **（1）多个线程同时修改一个共享变量**

- **（2）操作指令不是原子性的**
  
- **一条程序代码，可能对应多个CPU指令**【而[原子性](https://so.csdn.net/so/search?q=原子性&spm=1001.2101.3001.7020)，即指一个或多个操作在cpu中执行的过程中不被中断，称为“原子性”，操作系统做任务切换，可以发生在任何一条CPU 指令执行完，而不是高级语言里的一条语句。】
  
- **（3）操作系统调度管理线程执行**

  - java 并发程序都是基于多线程的，多个线程在执行过程中的执行顺序是由操作系统内核的调度机制决定的， 哪个线程在某一时刻获得CPU时间片并执行，由操作系统内核根据一些调度算法来管理。

  

例如上面代码中的`count += 1`，至少需要三条 CPU 指令。

- 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
- 指令 2：之后，在寄存器中执行 +1 操作；
- 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）
- 操作系统做任务切换，可以发生在任何一条CPU 指令执行完，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设 count=0，如果线程 A 在指令 1 执行完后做线程切换，线程 B先执行了这三条指令然后线程A才获取到时间片，继续之后指令2和指令3 ，两个线程都执行了 count+=1 的操作，但是得到的结果不是我们期望的 2，而是 1。
  ——————————————————————————————————————————————

## 2、java中如何解决原子性问题？

- 在 Java 中，可以借助`synchronized`、各种 `Lock` 以及各种**原子类**实现原子性。

- `synchronized` 

  - 任一时刻只有一个线程访问该代码块，

  - 只有当线程成功执行完`synchronized`代码块或方法，才会释放锁， 其他线程才可以获得锁并执行相同的代码块，因此可以保障原子性。

- 各种原子类是利用 **CAS** (compare and swap) 操作（可能也会用到 `volatile`或者`final`关键字）来保证原子操作。

## 3、讲一下CAS 

理解：

- （1）翻译过来就是比较和交换，**将比较和交换作为原子操作**，**`CAS`**操作是不可分割的，要么整个操作成功，要么整个操作失败，**并且由操作系统硬件来保证操作的原子性**。
- （2）CAS操作底层是通过Unsafe类使用**native本地方法**进行的CAS操作,cas操作是直接修改内存中的值。
  - CAS操作主要有三个参数：要更新的内存位置、**旧的期望值和新值**
    - 首先，获取要更新的**内存位置的值**，加载到线程的工作内存中，记作旧的期望值
    - 然后，将 **旧的值与var进行比较**，如果两者相等，则将**内存位置的值var更新为新值new**。
    - 如果两者不相等，则说明有其他线程修改了**内存位置的值var**，此时`CAS`操作失败，需要重新尝试
      - 在CAS（比较并交换）操作成功之后，CAS 操作会确保共享变量的值在主内存中被更新
      - 当一个线程执行CAS操作时，它的工作内存中的副本会被更新为新的值
      
      
  
- （3）CAS是一种**轻量级的同步机制**，主要用于**实现多线程环境下的无锁算法**，**可以在不使用锁（如synchronized、Lock）的情况下，对共享数据进行线程安全的操作。**使用无锁的方式，可以减少锁竞争带来的开销、以及线程间调度调来的开销
  
  - 【**Unsafe类**是JDK提供的一个**不安全的类**，它提供了一些底层的操作，包括内存操作、线程调度、对象实例化等。它的作用是让Java可以在底层**直接操作内存**】



### 3.1 cas是怎么实现原子性的（cas操作必须保证原子性）

- （1） **CAS 是一条 CPU 的原子指令，由操作系统硬件来保证操作的原子性**，保证的是比较和交换，这两个操作的原子性。

 硬件层面CAS又是如何保证原子性的呢？真的完全没加锁吗？

拿比较常见的x86架构的CPU来说，其实 CAS 操作通常使用 cmpxchg 指令实现的。

可是为啥 cmpxchg 指令能保证原子性呢？主要是有以下几个方面的保障：

```hxml
cmpxchg 指令是一条原子指令。在 CPU 执行 cmpxchg 指令时，处理器会自动锁定总线，防止其他 CPU 访问共享变量，然后执行比较和交换操作，最后释放总线。
cmpxchg 指令在执行期间，CPU 会自动禁止中断。这样可以确保 CAS 操作的原子性，避免中断或其他干扰对操作的影响。
cmpxchg 指令是硬件实现的，可以保证其原子性和正确性。CPU 中的硬件电路确保了 cmpxchg 指令的正确执行，以及对共享变量的访问是原子的。
```

所以，**在操作系统层面，CAS还是会加锁的，通过加锁的方式锁定总线**，避免其他CPU访问共享变量。
————————————————
原文链接：https://blog.csdn.net/Aqting/article/details/129465893

### 3.2存在的问题以及改进方法 

（1）ABA问题

> 1、CAS 容易造成ABA 问题
> 一个线程 将内存中的数值从a改成了b，接着又改成了a，此时CAS 认为是没有变化， 其实是已经变化过了，而这个问题的解决方案可以使用版本号标识， 每操作一次version 加1。在java5 中，已经提供了AtomicStampedReference 来解决问题。
>
> 2、不能保证代码块的原子性
> CAS 机制保证的一个共享变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3 个变量共同进行原子性的更新， 就不得不使用synchronized 了。
> 3、CAS 造成CPU 利用率增加
>
> 高并发下N多线程同时去操作一个变量，会造成大量线程CAS失败，然后处于自旋状态，导致严重浪费CPU资源，降低了并发性。
> ————————————————



# [#](#可见性) 可见性

**当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。**

## 1、Java中为什么会存在可见性问题？

- java虚拟机规范中定义了一种Java内存 模型（Java Memory Model，即JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。

- 根据JMM的内存读写规范，共享资源是存放在主存中的，每个线程都有自己的工作内存、工作内存中存储的是全局变量的副本，所有线程都共享一个主存。在并发的场景下，**多个线程对一个共享资源进行操作的时候是直接对自己工作内存的副本进行操作的，那么线程A对共享资源的操作其他线程就不可见，这就发生了内存可见性问题。**

## 2、解决方法

- **Lock**保证可见性

- **`synchronized`的内存语义包括了一种内存屏障的机制，这有助于确保线程可见性。**synchronized 靠操作系统内核的`Mutex Lock`（互斥锁）实现，相当于 `JMM` 中的 `lock`、`unlock`。退出代码块时刷新变量到主内存来保证可见性

  以下是`synchronized`如何保证线程可见性的原理：

  1. **进入同步块前的内存同步**：**当一个线程进入`synchronized`块之前，它会执行一个内存同步操作，将本地内存中的变量值与主内存中的值进行同步**，以确保它看到最新的值。这确保了线程在进入临界区之前具有最新的共享变量值。
  2. **退出同步块时的内存同步**：当线程退出`synchronized`块时，它会执行另一个内存同步操作，将修改的共享变量的值刷新回主内存，以使其他线程能够看到这个修改。这确保了在退出临界区后，共享变量的修改对其他线程可见。

- **volatile 保证可见性**

  - 当对volatile变量执行写操作后，**JMM**会把工作内存中的最新变量值强制刷新到主内存
  - 写操作会导致其他线程中的缓存无效

# [#](#有序性) 有序性

## 1、为什么会出现有序性问题？

- 简单来说就是系统在执行代码的时候并不一定是按照你写的代码的顺序依次执行。为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序。

- Java 源代码会经历 **编译器优化重排 —> 指令并行重排 —> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。

- **指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些线程不安全的问题。

我们上面讲重排序的时候也提到过：

> **指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些线程不安全的问题。

## 2、解决方案

- **synchronized**
  - **synchronized修饰的代码块部分依旧会发生指令重排**，但是由于`synchronized`可以保证**任一时刻只有一个线程访问该代码块/方法**，**从而保证了有序性**。

- **在 Java 中，`volatile` 关键字通过插入特定的内存屏障可以禁止指令进行重排序优化。**







# 二、JAVA 内存模型

- （1）从 CPU 缓存模型说起: **为了解决 CPU 处理速度和内存处理速度不对等的问题，引入了 CPU 缓存。**cpu的运行的时候并不是直接操作内存而是先把内存中的数据读到缓存，而内存的读和写操作可能会造成不一致的问题，**CPU 为了解决内存缓存不一致性问题可以通过制定缓存一致协议（比如 [MESI 协议](https://zh.wikipedia.org/wiki/MESI协议)**）或者其他手段来解决。不同的操作系统对这套理念有自己具体的实现。

  - 【不同的操作系统内存模型不同】

- （2）如果直接复用操作系统层面的内存模型，就可能会导致同样一套代码换了一个操作系统就无法执行了。Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。因此java虚拟机规范中定义了一种（Java Memory Model，即JMM）来**屏蔽掉【各种硬件】和【操作系统的内存访问】差异**，**以实现让Java程序在各种平台下都能达到【一致性】的【内存访问效果】。**

  

- （3）Java内存模型(即Java Memory Model，简称JMM)本身是一种抽象的概念，并不真实存在。

  - **它描述的是一组规则或规范，通过这组规范定义了程序中变量的访问方式，并且决定一个线程对共享变量的写入何时以及如何变为对另外的线程可见、**其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程**要遵守哪些和并发相关的原则和规范**， 解决在并发编程下像 **多级缓存和指令重排**这类设计可能会导致程序运行出现一些问题。

- java内存模型规定所有的变量都存储在主内存中。**每个线程都有自己的工作内存**，线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行。线程不能直接读写主内存中的变量

  - 【即一个变量如何从主内存拷贝到工作内存，如何从工作内存同步到主内存之间的实现细节，Java 内存模型定义来以下八种同步操作】不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成。

  我可以理解为JAVA内存模型 实质上就是一套规范，除了抽象了线程和主内存之间的关系之外，其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。

  ![image-20231024120204306](C:\Users\16055\AppData\Roaming\Typora\typora-user-images\image-20231024120204306.png)

# **三、volatile** 

## 1、volatile是什么？

- `volatile`是**`java`**中的一个关键字，用来修饰共享变量。

- 特点：

  **被volatile修饰的共享变量满足【有序性】和【可见性】两大特点**

- **对应的内存语义：**

  一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

  - 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
    - 当我们写一个`volatile`变量的时候，`JMM`会把该线程对应的工作内存中的共享变量值立即刷回到主存中，这个写回操作会使得其他线程工作的内存中的该变量副本失效。当我们读**volatile**变量的时候，会从主存中读取该共享变量最新的值。
  - 2）禁止进行指令重排序，保证了一定程度上的有序性。
    - 禁止指令重排序：使用 `volatile` 关键字修饰一个变量时，它告诉编译器和处理器，不要对这个变量的读取和写入进行重排序。这意味着在 `volatile` 变量的写操作之前，所有之前的操作都会被完成，而在 `volatile` 变量的读操作之后，所有后续的操作将会等待它完成。

## 2、volatile有什么作用？

**总结来说 ：保证可见性，禁止指令重排序**保证有序性

## 3、如何禁止指令重排

 如果我们将变量声明为 **`volatile`** ，在对这个变量进行读写操作的时候，（1）**`JMM`的重排规则会要求`JVM`编译器在生成`JVM`指令时插入特定的内存屏障指令**。（2）内存屏障确保指令在进行重排的时候不会把后面的指令排到内存屏障之间的位置，也不会把前面的指令排到内存屏障之后的位置，即在执行内存屏障指令的时候，在它前面的操作已经完成了，实现了一定程度中的有序性。

### 什么是指令重排序？

-  简单来说就是系统在执行代码的时候并不一定是按照你写的代码的顺序依次执行。为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序。

- Java 源代码会经历 **编译器优化重排 —> 指令并行重排 —> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。

- **指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些线程不安全的问题。

- 编译器和处理器的指令重排序的处理方式不一样。

  - 对于编译器，通过禁止特定类型的编译器重排序的方式来禁止重排序。
  - 对于处理器，通过插入内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）的方式来禁止特定类型的处理器重排序。
  - 指令并行重排和内存系统重排都属于是处理器级别的指令重排序。

  

### 内存屏障

内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）**是一种 指令，用来禁止处理器指令发生重排序（像屏障一样），从而保障指令执行的有序性**。

![image-20231020205555626](C:\Users\16055\AppData\Roaming\Typora\typora-user-images\image-20231020205555626.png)

## 3、volatile保证可见性的就意味着：

volatile修饰共享变量，那么**它会保证修改的值会立即被更新到主内存，当有其他线程需要读取时，会从主存中读取数据，可以立即获取修改之后的值**。

- 当对volatile变量执行写操作后，处理器会把工作内存中的最新变量值强制刷新到主内存
- 写操作会导致其他线程中的缓存无效
- 当有其他线程需要读取时，会从主存中读取数据，可以立即获取修改之后的值

http://t.csdn.cn/xGxwX

## 4.volatile如何保证共享变量可见性？

- **java代码**层面 ：`volatile`用来修饰Java变量，这就指示编译器，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。
- **字节码**层面，就是使用访问标志：**`ACC_VOLATILE`**来表示，供后续操作此变量时判断访问标志是否为`ACC_VOLATILE`，来决定是否遵循`volatile`的内存语义处理。
- `JMM`层面 ：**`JMM`的重排规则**会要求`JVM`编译器在生成**JVM指令**时插入特定的内存屏障指令
  - 内存屏障提供了3个功能，它会使得对volatile修饰的变量进行修改之后，**会强制将修改写回主内，刷新主内存值之后，强制过期其他线程的工作内存，当有其他线程需要读取时，会从主存中读取数据**。
    - 【即一个变量如何从主内存拷贝到工作内存，如何从工作内存同步到主内存之间的实现细节，Java 内存模型定义来八种同步操作】
  - 对变量加了volatile之后，编译成指令的前后加了如下的四个屏障，其中Load表示读，Store表示写。
      ![image-20231028121109432](C:\Users\16055\AppData\Roaming\Typora\typora-user-images\image-20231028121109432.png)
    - ①在每个volatile读操作之前插入LoadLoad屏障，这样就能让当前线程获取A变量的时候，保证其他线程也能获取到相同的值，这样所有线程读取到的数据就一样了。
      ②在每个volatile写操作之前插入StoreStore屏障，这样就能让其他线程修改A变量之后，把修改的值对当前线程可见。
      ③在读操作之后插入LoadStore屏障；这样就能让当前线程在其他线程修改A变量之前，获取到主内存里面A变量的值。
      ④在写操作之后插入StoreLoad屏障；这样就能让其他线程在获取A变量的时候，能够获取到已经被当前线程修改的值。
      ————————————————
  
- **从CPU指令的角度** ：当.class文件被编译为cpu可以执行的指令的时候，会在加了volatile修饰的变量前面加上以lock为前缀的指令。这就引发了两件事情（1）当对该变量进行写操作的时候，锁住缓存行，cpu立马将缓存行中的数据写回主存，这个写回操作会使得其他cpu缓存行中对应变量的数据失效。【这是因为使用volatile【lock会让缓存一致性协议生效】会开启**缓存一致性协议**：当线程修改了某个共享变量的值，该修改会立马同步回主存，其他线程可以通过**总线嗅探机制**感知这种变化从而使得自己工作内存中的数据失效，从而在再在次需要的时候从主存中读取】

## 5、synchronized 和 volatile 有什么区别？

volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
**volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞**
————————————————



## 6、reentrantLock 和synchronized区别

`ReentrantLock`是基于[AQS](https://so.csdn.net/so/search?q=AQS&spm=1001.2101.3001.7020)实现的一种可重入锁


# 四、synchronized

## 1、讲一下synchronized？

### **是什么？===> 有什么作用？==>synchronized的两大特性===>如何保证原子性、有序性、可见性**

- `synchronized` 是 Java 中的一个关键字，可以用来修饰同步代码块、实例方法、静态方法,它具有两大特性 ：可重入性 和不可中断性。

- **关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行被synchronized修饰的某个方法或者某个代码块**。是一种重量级的同步策略
- **任一时刻只有一个线程访问该代码块/方法**【线程要执行被synchronized修饰的某个方法或者某个代码块的时候，会尝试去获取锁，获取锁成功后才能去执行，当一个线程获取锁成功之后，在同一个时刻，**其他线程只能处于【等待/阻塞】的状态**。】
  
- 只有当线程成功执行完`synchronized`代码块或方法，/ 或者抛出异常了 才会释放锁， 其他线程才可以获得锁，获取锁成功才能执行相同的代码块，**【因此可以保障原子性。】**
  
- synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能),【**synchronized 靠操作系统内核的Mutex Lock（互斥锁）实现，相当于 JMM 中的 lock、unlock。退出代码块时刷新变量到主内存来保证可见性。**】

  - **进入同步块前的内存同步-lock指令**：当一个线程进入`synchronized`块之前，它会执行一个内存同步操作，将本地内存中的变量值与主内存中的值进行同步，以确保它看到最新的值。这确保了线程在进入临界区之前具有最新的共享变量值。
  - **退出同步块时的内存同步-unlock指令**：当线程退出`synchronized`块时，它会执行另一个内存同步操作，将修改的共享变量的值刷新回主内存，以使其他线程能够看到这个修改。这确保了在退出临界区后，共享变量的修改对其他线程可见。 

- **synchronized修饰的代码块部分依旧会发生指令重排**，但是由于`synchronized`可以保证**任一时刻只有一个线程访问该代码块/方法**，**从而保证了有序性**。

原文链接：https://blog.csdn.net/qq_48435252/article/details/123980558

### 1.1 两大特性

- 可重入性：
  - 锁对象内部有一个计算器记录线程获取了几次锁，每执行一次同步代码块，计数器数量减去1，如果计数器数量为0，则释放该锁。使用可重入锁可以避免死锁，更好地封装代码【例如：在同步代码块内部还有一个同步代码块】
- 不可中断：是指一个线程获取了锁，另外一个线程也要获取锁的话，那么它会一直处于等待或者阻塞状态并且是不可中断的。

## 2、synchronized的使用方法以及使用场景

**synchronized是一把悲观的互斥锁、用于多个线程操作共享数据时，加锁保证访问共享数据的线程安全性。**

**可以用来修饰同步代码块、实例方法、静态方法。构造方法本身就属于线程安全的，因此不能使用synchronized来修饰**

- **1、修饰实例方法** （锁当前对象实例）

  给当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁** 。

- **2、修饰静态方法** （锁当前类）

  给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**。

- **3、修饰代码块** （锁指定对象/类）

  对括号里指定的对象/类加锁：

  - `synchronized(object)` 表示进入同步代码库前要获得 **给定对象的锁**。
  - `synchronized(类.class)` 表示进入同步代码前要获得 **给定 Class 的锁**

  ------

## 3、synchronized的底层原理

### 3.1 怎么实现同一时刻只有1个线程执行被synchronized所修饰的方法

**synchronized使用Object对象充当锁。**

**使用对象作为锁的基本原理是**：每个对象都有一个相关的监视器锁（也称为内置锁或互斥锁）。当线程试图获取锁时，它实际上是在尝试获取该对象的监视器锁（monitor）。只有一个线程可以成功地获取该监视器锁，并且其他线程将被阻塞。【**因为它有参数count 来记录是否已经被线程持有**】不管是正常执行还是异常出错最后都会释放锁，处于**阻塞/等待**的线程再来抢占锁。

====>实现同一时刻只有1个线程执行被synchronized所修饰的方法/代码块。



**（1）synchronized的底层实现是完全依赖JVM虚拟机的，具体而言是依赖对象头中的monitor机制来实现的**，**使用sychronized获取锁实则是获取monitor的持有权**。

**（2）monitor是一个监视器锁，每个java实例对象都关联着一个monitor对象，使用sychronized获取锁实则是获取monitor的持有权【monitor底层是通过操作系统的mute lock 来实现的，它涉及到用户态和内核态的切换，所以它是一个重量级的锁】，monitor对象中有变量用来记录持有锁的线程id、锁重入的次数并且提供两个命令monitorEnter 和monitorExit**

【同步代码块中】

**`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。**

上面的字节码中包含一个 `monitorenter` 指令以及两个 `monitorexit` 指令，这是为了保证锁在同步代码块代码正常执行以及出现异常的这两种情况下都能被正确释放。当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 **对象监视器 `monitor`** 的持有权。

------

`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，隐式调用monitorEnter 和monitorExit从而执行相应的同步调用。

#### 对象头

- HotSpot 虚拟机中，对象在内存中存储的布局可以分为三块区域：**对象头**（Header）、**实例数据**（Instance Data）和**对齐填充**（Padding）。

  - 实例数据：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。 

  - 填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。

  - 对象头：对象头主要结构是由Mark Word 和 Class point组成

    - **Mark Word** ：存储对象的hashCode、锁类型状态等信息或分代年龄或GC标志等信息

      - ptr_to_heavyweight_monitor：指向monitor对象（也称为管程或监视器锁）的起始地址，每个对象都存在着一个monitor与之关联，但当一个monitor被某个线程持有后，它便处于锁定状态。
        ————————————————
        原文链接：https://blog.csdn.net/weixin_42460087/article/details/126474481

    - **Class point**: 是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例

      ![img](https://img-blog.csdnimg.cn/e91870bb482e458d98cbb4619694a36e.png)

#### Monitor监视器锁

monitor是由`ObjectMonitor`实现的,monitor对象是有jvm来创建的

- `ObjectMonitor`中有两个队列，`_WaitSet` 和 `_EntryList`，用来保存`ObjectWaiter`对象列表( 每个等待锁的线程都会被封装成`ObjectWaiter`对象)，_
- `owner`指向持有`ObjectMonitor`对象的线程，当多个线程同时访问一段同步代码时，首先会进入 `_EntryList `集合，当线程获取到对象的`monitor` 后进入` _Owner `区域并把`monitor`中的`owner变量`设置为当前线程同时`monitor`中的计数器`count`加1，
- 若线程调用` wait() `方法，将释放当前持有的`monitor`，owner变量恢复为null，count自减1，同时该线程进入` WaitSet`集合中等待被唤醒。
- 若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示:
- ![在这里插入图片描述](https://img-blog.csdnimg.cn/11a20833b69a440a8a87c31d537c225a.png)————————————————
  原文链接：https://blog.csdn.net/weixin_42460087/article/details/126474481



【看黑马的视频 

【Java面试热点问题，synchronized原理剖析与优化】 https://www.bilibili.com/video/BV1aJ411V763/?p=19&share_source=copy_web&vd_source=0e4bfae67e1331d774739c8b422d75df】 

## 4、JDK1.6 之后的 synchronized 底层做了哪些优化？

**JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。**

- 在 JDK 1.6之前，**synchronized 还是一个重量级锁**，是一个效率比较低下的锁，synchronized的底层实现是完全依赖JVM虚拟机的，具体而言是依赖对象头中的monitor机制来实现的**，**使用sychronized获取锁实则是获取monitor的持有权。

  - **因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的**，挂起线程和恢复线程都需要转入内核态去完成，阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成(用户态和内核态之间的切换，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长

    - 挂起线程和恢复线程确实涉及到用户态和内核态之间的切换，这是因为线程的调度和管理通常是由操作系统来处理的。在Java中，线程的挂起和恢复可以使用`wait()`和`notify()`或者`notifyAll()`方法来实现，这些方法通常用于线程之间的协调和同步。

      当一个线程调用`wait()`方法时，它会释放它所持有的锁，并进入等待状态。这需要将线程从用户态切换到内核态，因为操作系统需要管理线程的状态以及线程的等待队列。当另一个线程调用`notify()`或者`notifyAll()`方法来唤醒等待的线程时，也需要将CPU从内核态切换回用户态，以便唤醒线程可以继续执行。

- 但是在JDK 1.6后，Jvm为了**提高锁的获取与释放效率**对（**synchronized** ）进行了优化，引入了 **偏向锁 和 轻量级锁** ，从此以后锁的状态就有了四种（无锁、偏向锁、轻量级锁、重量级锁），**并且四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级（从低级别到高级别），不能锁降级（高级别到低级别）**，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。
  ————————————————————————————————————————————————

原文链接：https://blog.csdn.net/jinxinxin1314/article/details/106181844

------

## 5、Synchronized锁的升级过程

Java SE 1.6 为了减少获得锁和释放锁带来的性能消耗，引入了 “偏向锁” 和 “轻量级锁”：锁一共有 4 种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。锁可以升级但不能降级。

**锁的类型和状态在对象头Mark Word中都有记录，在申请锁、锁升级等过程中JVM都需要读取对象的Mark Word数据**

### 偏向锁 

偏向锁：大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能

#### 偏向锁原理 

- **当线程第一次访问同步代码块的时候**，**jvm会将对象头中的标志位设置为01，偏向锁设置为1，**

- **同时使用CAS操作把获取这个锁的线程ID记录在对象头的MarkWord中**，
- 如果CAS操作成功，**以后该线程在进入同步块时先判断对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果存在就直接获取锁，无需其他的操作**。如果CAS操作失败： 说明可能出现了竞争 ，偏向锁要升级为轻量级锁。

### 轻量级锁

轻量级锁：**是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁**，其他线程会通过自旋（关于自旋的介绍见文末）的形式尝试获取锁，线程不会阻塞，从而提高性能。。【是为了减少重量级锁带来的消耗。】

#### 轻量级锁原理 

偏向锁出现竞争，就会转化为轻量级锁

- 首先，会判断当前对象是否处于无锁状态，如果是则jvm首先会在当前栈帧中建立一个名为锁记录的空间，用于存储当前对象的markWord的拷贝，并且将所记录中的owner指向当前对象

- jvm利用CAS操作尝试将锁对象的markWord更新为指向锁记录的指针

  - 如果成功表示竞争到锁，并且将锁标志位修改为00

  - 如果失败 

    - （1）判断当前锁是否已经被当前线程持有，是的话就执行同步代码块
    - （2）如果已经被其他线程持有，那么该线程就自旋尝试获取锁、
      - 到达一定的自旋次数还是没有获取到锁，那就升级为重量级锁

    

### 重量级锁

锁在原地循环等待的时候，是会消耗CPU资源的。所以自旋必须要有一定的条件控制，否则如果一个线程执行同步代码块的时间很长，那么等待锁的线程会不断的循环反而会消耗CPU资源。默认情况下锁自旋的次数是10 次，可以使用-XX:PreBlockSpin参数来设置自旋锁等待的次数。10次后如果还没获取锁，则升级为重量级锁。

- 当锁升级为重量级锁后，未抢到锁的线程都会被阻塞，进入阻塞队列。

synchronized的执行过程

    检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
    如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
    如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
    当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
    如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
    如果自旋成功则依然处于轻量级状态。
    如果自旋失败，则升级为重量级锁。
————————————————————————————————————————————————

# 	AQS 

## 1、解释一下AQS是什么？

翻译过来的意思就是**抽象队列同步器**，本质上AQS 就是一个抽象类，提供了一些通用功能的实现，**主要用来构建锁和同步器**，是整个JUC体系的基石。比如ReentrantLock 就是基于AQS来实现的。

-  AQS提供了两种锁的机制： 分别是排他锁和共享锁。
  排它锁: 多个线程竞争同一共享资源的时候, 同一时刻只允许一个线程去访问共享资源, 比如lock中的ReentrantLock的一个实现就是用到了AQS中的排它锁的功能。
  共享锁: 读锁,同一时刻允许多个线程同时访问同一资源, 比如CountDownLatch, Semaphore.
  AQS需要解决3个核心的问题:
  1.互斥变量的设计,以及如何保证多线程更新互斥变量的时候线程的安全性
  2.未竞争到锁资源的线程的等待, 以及竞争到锁资源释放锁的唤醒
  3.锁竞争的公平性和非公平性


**AQS核心思想是**：

- （1）如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。
- （2）如果被请求的共享资源被占用，那么就需要一套**线程阻塞等待**以及**被唤醒时锁分配的机制**。
- （3）这个机制AQS是用**CLH队列锁**实现的，CLH 锁是对自旋锁的一种改进，**是一个虚拟的双向队列**，即将暂时获取不到锁的线程加入到队列中。
- （4） 通过内置的FIFO队列来完成获取资源线程的排队工作，AQS使用CAS对该同步状态进行原子操作实现对其值的修改，AQS使用一个voliate int成员变量来表示同步状态。
  - AQS采用了一个int类型的互斥变量state, 用来记录锁的状态, 0表示当前无任何线程竞争锁资源, >=1表示有多个线程竞争锁资源, 一个线程来获取锁资源的时候, 首先会判断state是否等于0, 先判断是否为无锁状态, 如果是, 这修改state=1,如果多个线程访问的时候, 会导致线程安全性问题, 因此AQS采用了CAS机制, 保证state互斥变量的一个原子性。
    未获取到锁的线程通过unsafe中的park方法去进行阻塞, 把阻塞的线程按照先进先出的原则加入到一个双向链表CHL的结构中, 当获取锁资源的线程释放资源的时候, 会从双向链表的头部唤醒下一个等待的线程, 再去竞争锁, 最后关于锁竞争的公平性和非共平行问题上, AQS利用公平锁需要去判定双向链表中有无阻塞的线程, 如果有的话排队等待, 非公平锁是不管有无等待锁线程, 会直接去尝试修改state的值, 获取锁的资源。
    ————————————————

# reentrantLock

## 1、reentrantLock的介绍 

`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，它类似于Synchronized互斥锁，可以保证线程安全。**它手动加锁、解锁，支持公平锁**等。

**ReentrantLock主要利用CAS+AQS队列来实现**

## reentrabtLock 和synchronized 的区别

① **底层实现**上来说，synchronized 是**JVM**层面的锁，是**Java关键字**，通过monitor对象来完成（monitorenter与monitorexit），对象只有在同步块或同步方法中才能调用wait/notify方法，ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的**API层面**的锁。

synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，ReentrantLock实现则是通过利用CAS（CompareAndSwap）自旋机制保证线程操作的原子性和volatile保证数据可见性以实现锁的功能。

② **是否可手动释放：**

synchronized 不需要用户去手动释放锁，synchronized 代码执行完后系统会自动让线程释放对锁的占用；   ReentrantLock则需要用户去手动释放锁，如果没有手动释放锁，就可能导致死锁现象。一般通过lock()和unlock()方法配合try/finally语句块来完成，使用释放更加灵活。

③ **是否可中断**

synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成；  ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit  unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断。

④  **是否公平锁**

synchronized为非公平锁  ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁。

⑥ **锁的对象**

synchronzied锁的是对象，锁是保存在对象头里面的，根据对象头数据来标识是否有线程获得锁/争抢锁；ReentrantLock锁的是线程，根据进入的线程和int类型的state标识锁的获得/争抢。

# 四、使用多线程可能带来什么问题?

**内存泄漏、死锁、线程不安全等等**。



# 五、线程不安全

> 线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份共享数据数据的正确性和一致性。
>
> 线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。

## 5.1什么是线程不安全（描述这种现象）

多个线程访问一个**共享资源**（线程安全问题都是由全局变量及[静态变量](https://so.csdn.net/so/search?q=静态变量&spm=1001.2101.3001.7020)引起的。）可能出现结果与预期结果不正确的现象

## 5.2对于开发者，什么情况下会出现线程不安全？

什么情况下会数据不安全呢，要满足两个条件：一是数据共享（临界资源），二是多线程同时访问并改变该数据。



## 5.3 为什么上述情况 会出现线程不安全？

------

- 造成线程不安全的根本原因 ：多线程环境下**线程抢占式执行 、多个线程共享同一份共享资源、并发对共享资源进行修改操作**而没有**同步策略** 导致结果与预期结果不同。

- 出现该问题的根源是：

  - [线程不安全问题出现的原因： ](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t0)

    [1、抢占式执行](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t1)

    >  多个线程在执行过程中的执行顺序是由操作系统内核的调度机制决定的，调度是指决定哪个线程在某一时刻获得CPU时间片并执行。这是一个复杂的过程，由操作系统内核根据一些调度算法来管理。

     

    [2、多个线程同时修改一个变量](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t2)

    

    [3、操作指令不是原子的](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t3)

    **一条程序代码，可能对应多个CPU指令**【而[原子性](https://so.csdn.net/so/search?q=原子性&spm=1001.2101.3001.7020)，即指一个或多个操作在cpu中执行的过程中不被中断，称为“原子性”，操作系统做任务切换，可以发生在任何一条CPU 指令执行完，而不是高级语言里的一条语句。】

    [4、内存可见性问题](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t4)

    根据JMM的内存读写规范，共享资源是存放在主存中的，每个线程都有自己的工作内存、工作内存中存储的是全局变量的副本，所有线程都共享一个主存。在并发的场景下，**多个线程对一个共享资源进行操作的时候是直接对自己工作内存的副本进行操作的，那么线程A对共享资源的操作其他线程就不可见，这就发生了内存可见性问题。**

    [5、指令重排序](https://blog.csdn.net/m0_67683346/article/details/126783051?csdn_share_tail={"type"%3A"blog"%2C"rType"%3A"article"%2C"rId"%3A"126783051"%2C"source"%3A"unlogin"}#t5)

    - 简单来说就是系统在执行代码的时候并不一定是按照你写的代码的顺序依次执行。为了提升执行速度/性能，计算机在执行程序代码的时候，会对指令进行重排序。

    - Java 源代码会经历 **编译器优化重排 —> 指令并行重排 —> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。

    - **指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致** ，所以在多线程下，指令重排序可能会导致一些线程不安全的问题。



## 5.4 保证线程安全的策略

（1）加锁 sycgronized 、lock等

（2）使用CAS、原子类（**AtomicInteger**）

（3）**线程本地存储**（局部变量、threadLocal）

# 六、死锁

线程死锁描述的是这样一种情况：**多个线程同时被阻塞**，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

上面的例子符合产生死锁的四个必要条件：

1. 互斥条件：该资源任意一个时刻只由一个线程占用。

2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。

3. 不剥夺条件: 线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。

4. 循环等待条件: 若干线程之间形成一种头尾相接的循环等待资源关系。

   如何预防和避免线程死锁?

   **如何预防死锁？** 破坏死锁的产生的必要条件即可：

   1. **破坏请求与保持条件**：一次性申请所有的资源。
   2. **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
   3. **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

   **如何避免死锁？**

   避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

   ------

    

# 七、内存泄露

## 1、什么是内存泄漏

某个对象不再有用，但是占用的内存却不能被回收。

**不再会被使用的对象或者变量占用的内存不能被回收**，就是内存泄露。

# 八、ThreadLocal

## 1、讲一下ThreadLocal？

### **ThreadLocal是什么？=>有什么作用？=>使用场景=>原理**

**（1）是什么？**

**`ThreadLocal`** 是线程本地变量，创建`ThreadLocal`类型的变量，会在每个线程的工作内存中都创建一份,**实现每一个线程都有自己的专属本地变量**.每个线程对这个对象的访问实际上都是对当前线程中该变量的副本进行操作，别的线程并不能获取到当前线程的副本值。

**（2）作用：**

- **实现将变量和线程绑定.**

-  **在一个线程内部该变量是共享的，提供了get和set方法进行操作。线程与线程之间该变量是隔离的。**【变量在线程间隔离而在方法或类间共享的场景】

- 通过`ThreadLocal`的包装使得该变量可以在`线程之间隔离`和`当前线程全局共享`。

  ------

   

**（3）原理：**

每个**Thread**维护一个`ThreadLocalMap`对象，这是一个定制的`Map`，这个**Map**的**key**是`ThreadLocal实例对象`，`value`是`ThreadLocal`实例对象调用set方法()设置的值， 并且`ThreadLocal`类提供了set 和get方法向map获取和设置变量值;。

- 每个Thread线程内部都有一个Map（`ThreadLocalMap::threadlocals`）;
- Map里面存储`ThreadLocal`对象（key）和线程的变量副本（value）;【ThreadLocal本身不存储值】
- Thread内部的Map由`ThreadLocal`维护，`ThreadLocal`类提供了set 和get方法向map获取和设置变量值;。
  - 使用set()方法的时候，会先获取当前线程，然后获取当前线程的`ThreadLocals`，将`threadLocal `这个对象作为`key`值，属性值作为`Value`存放在`ThreadLocals`这个Map中，get方法类似。
  - 对于不同的线程，每次获取副本值时，别的线程不能获取当前线程的副本值，就形成了数据之间的隔离。

**(4) 使用场景**

一般情况下,**如果多个线程之间需要共享资源**,以达到线程之间的通信功能,就使用同步机制。

如果仅仅需要隔离多个线程之间的**共享冲突**,则可以使用`ThreadLocal`。

 

## 2、ThreadLocalMap是怎么解决hash冲突的。

 ThreadLocalMap使用[线性](https://so.csdn.net/so/search?q=线性&spm=1001.2101.3001.7020)探测法（开放寻址法）来解决哈希冲突

## 3、ThreadLocal存在的问题，怎么解决

存在内存泄漏问题 

### 3.1 为什么会存在内存泄漏问题？

**由于`ThreadLocalMap`的生命周期跟`Thread`一样长，如果没有手动删除对应`Entry`就会导致内存泄漏。这是根源原因。**

### 3.2 ThreadLocal 内存泄露问题是怎么导致的？

#### (三) 弱引用(WeakReference)

java中使用WeakReference来表示弱引用。如果某个对象与弱引用关联，那么当JVM在进行[垃圾回收](https://so.csdn.net/so/search?q=垃圾回收&spm=1001.2101.3001.7020)时，无论内存是否充足，都会回收此类对象。



`ThreadLocalMap`使用`Thread  Local`的弱引用作为`key`，如果一个`ThreadLocal`没有外部强引用来引用它，那么系统 GC 的时候，这个`ThreadLocal`势必会被回收，这样一来，`ThreadLocalMap`中就会出现`key`为`null`的`Entry`，就没有办法访问这些`key`为`null`的`Entry`的`value`，如果当前线程再迟迟不结束的话，这些`key`为`null`的`Entry`的`value`就会一直存在一条强引用链：`Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value`永远无法回收，造成内存泄漏。

### 3.3 解决方法

`ThreadLocalMap` 实现中已经考虑了这种情况，**在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。**

**使用完 `ThreadLocal`方法后最好手动调用`remove()`方法**

3.4 为什么key为弱引用

- **key 使用强引用**：引用的`ThreadLocal`的对象被回收了，但是`ThreadLocalMap`还持有`ThreadLocal`的强引用，如果没有手动删除，`ThreadLocal`不会被回收，导致`Entry`内存泄漏。
- **key 使用弱引用**：引用的`ThreadLocal`的对象被回收了，由于`ThreadLocalMap`持有`ThreadLocal`的弱引用，即使没有手动删除，`ThreadLocal`也会被回收。`value`在下一次`ThreadLocalMap`调用`set`,`get`，`remove`的时候会被清除。

比较两种情况，我们可以发现：由于`ThreadLocalMap`的生命周期跟`Thread`一样长，如果都没有手动删除对应`key`，都会导致内存泄漏，但是使用弱引用可以多一层保障：**弱引用`ThreadLocal`不会内存泄漏，对应的`value`在下一次`ThreadLocalMap`调用`set`,`get`,`remove`的时候会被清除**。



# 九、线程

# 1、讲一下对线程和进程的理解？

## **1.0 线程是什么 ？===> 进程是什么？ ===> 进程和线程的区别及优缺点？？**

- 进程是程序的一次执行过程，是**系统运行程序**的基本单位。
- 而线程是**进程中执行任务的最小单位，是**处理器[任务调度](https://so.csdn.net/so/search?q=任务调度&spm=1001.2101.3001.7020)和执行的基本单位。
- **理解 ：**

  - 【进程是操作系统资源分配的基本单位】一个在内存中运行的应用程序，**每个进程都有自己独立的一块内存空间**，比如在Windows系统中，一个运行的QQ.exe就是一个进程。
  - QQ这个程序启动之后，点击发送消息这个窗口 实则是一个进程，**线程是处理器任务调度和执行的基本单位**，**一个进程可以有多个线程**。
- **区别 ：**

  - **根本区别**：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
  - **资源开销**：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享所属进程程资源。
  - **所处环境**：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（===>实则是通过CPU调度，在每个时间片中只有一个线程执行。
  - 关系：一个进程至少有一个线程，线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
- **线程的优势**





## 1.1 从 JVM 角度说进程和线程之间的关系（重要）

**启动main方法运行一个java程序实则是启动了一个jvm进程。**

**jvm进程是 main 线程和多个其他线程同时运行**。

- 一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)\**资源，***

- ***但是每个线程有自己的\**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

  - 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理**。在多线程的情况下，程序计数器用于记录当前线程执行的位置**，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。

    **===》程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。**

  - 虚拟机栈：每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
    本地方法栈：和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

    **====》为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。**



## 1.2 线程的状态 

Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

- NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。

- **RUNNABLE**: 运行状态，线程被调用了 `start()`等待运行的状态。【线程这时候处于 **READY（可运行）** 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）** 状态。】

- BLOCKED：阻塞状态，**需要等待锁释放。**

- WAITING：等待状态，**进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态。**

- TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。

- TERMINATED：终止状态，表示该线程已经运行完毕。

------

## 1.3 使用线程的3种方法

- 1.继承Thread类，重写run方法，启动的时候直接创建Thread类的子类对象，调用该对象的start()方法
   2.实现Runnable接口，重写run方法，启动的时候创建Thread对象，并且将实现了Runnable接口的类对象作参数传入创建Thread对象的构造方法中
   3.使用Callable接口和FutureTask类

```java
public class ThreadOne extends Thread{
    @Override
    public void run() {
        System.out.println("当前线程："+Thread.currentThread().getName());
    }
}

 // -------main() 函数
 public static void main(String[] args) throws Exception {
        ThreadOne threadOne = new ThreadOne();
        threadOne.start();
    }
// 输出 

```



## 1.4 线程通信的方法

- 基于共享内存 和消息传递

#### 方式一：使用 *volatile* 关键字

基于 ***volatile*** 关键字来实现线程间相互通信是**使用共享内存的思想**，

- **`volatile` 关键字可以保证变量的可见性**，如果我们将变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。
- 大致意思就是多个线程同时监听一个变量，当这个变量发生变化的时候 ，线程能够感知并执行相应的业务。

#### **方式二：使用Object类的wait() 和 notify() 方法**

Object类提供了线程间通信的方法：wait()、notify()、notifyaAll()，它们是多线程通信的基础，而这种实现方式的思想自然是线程间通信。

    注意： wait和 notify必须配合synchronized使用，wait方法释放锁，notify方法不释放锁

————————————————————————————————————————————————
原文链接：https://blog.csdn.net/jisuanji12306/article/details/86363390

## 1.5 进程间通信的方法

进程之间通信（IPC）通常需要使用操作系统提供的机制，如**管道、消息队列或共享内存**





# 十-线程池

# 为什么会有线程池？

- **线程是一个重资源**，JVM 中的线程与操作系统的线程是一对一的关系，所以在 JVM 中每创建一个线程就需要调用操作系统提供的 API 创建线程，赋予资源，并且销毁线程同样也需要系统调用。
- 而系统调用就意味着上下文切换等开销，并且线程也是需要占用内存的，而内存也是珍贵的资源。**因此线程的创建和销毁是一个重操作**，并且线程本身也占用资源。
- **多线程的主要是为了提高 CPU 的利用率。但是线程数并不是越多越好**
  - 线程的切换需要开销，比如替换寄存器的内容、高速缓存的失效，如果线程数太多，切换的频率就变高，可能使得多线程带来的好处抵不过线程切换带来的开销，得不偿失
  - 线程数太少，会使得cpu利用率低

===>**线程池就是管理【一系列线程】的【资源池】**，**其提供了一种限制和管理线程资源的方式**。

# 4.1、线程池是什么？

- 线程池是一种<u>利用**池化技术思想**</u>来实现的【<u>**线程管理技术**</u>】，主要是为了复用已经创建好的线程、便利地管理线程和任务、并将线程的创建和任务的执行解耦开来。我们可以创建线程池来复用已经创建的线程来
  - **降低频繁创建和销毁线程所带来的资源消耗**。
  - **提高效应速度：**当任务到达的时候，任务可以不需要等到线程创建就能立即执行
  - **提高线程的可管理性**：使用线程池可以进行统一的分配

# 4.2、使用场景



# 4.3、线程池的优缺点

> ### 优点

- **降低资源消耗** ： 重复利用已经创建的线程降低线程创建和销毁造成的损耗，【当我们线程创建过多时，容易引发内存溢出】

- **提高效应速度：**当任务到达的时候，任务可以不需要等到线程创建就能立即执行
- **提高线程的可管理性**：使用线程池可以进行统一的分配



# 4.4、线程池的使用

## 0、线程池的工作流程\工作原理

线程池中比较核心的参数有：核心线程数、最大线程数、任务队列、拒绝策略

 简单来说线程池把任务的提交和任务的执行剥离开来，当一个任务被提交到线程池之后：

- 如果此时线程数小于核心线程数，那么就会新起一个线程来执行当前的任务。
- 如果此时线程数大于核心线程数，那么就会将任务塞入阻塞队列中，等待被执行。
- 如果阻塞队列满了，并且此时线程数小于最大线程数，那么会创建新线程来执行当前任务。
- 如果阻塞队列满了，并且此时线程数大于最大线程数，那么会采取拒绝策略。

### 工作原理

线程池中有一个`AtomicInteger`类型的变量，叫做`ctl`。这个变量的前3位用来表示当前线程池的状态，低29位用来表示线程池中工作线程的数量。通过`CAS`操作来修改线程池中工作线程的数量，通过`reentrantLock`来保证多线程情况下操作的线程安全。

使用`execute(task)`来提交一个任务到线程池中去

- 首先会判断任务是否为空，为空就抛出异常，然后通过`ctl变量`的值得出当前线程池所处的状态和工作线程的数量。
- 如果当前工作线程数少于核心线程数，就调用`addWork()方法`，在**`addWorker()`**方法中先判断线程池的状态，再判断线程池中的工作线程的数量，**如果判断通过就使用`CAS操作`更新工作线程数`wc`**。更新成功之后 通过`worker类`的构造方法创建`worker对象`，在worker构造方法中`this.thread = getThreadFactory().newThread(this)`通过线程池设定的线程工厂来创建线程。实现将线程和worker的绑定，调用`start()`方法启动的时候实际上运行`run()`方法，但是在worker类中重写了`run()`方法，实际运行时`runworker()方法`，这一段会使用`reentrantLock` 来保证线程安全。 在`runworker()方法`中有一个循环 `while (task != null || (task = getTask()) != null)`让线程进行工作，在循环内部调用任务的run()方法执行具体的任务，执行完线程创建时绑定的任务之后，通过**`getTask()`**去任务队列中循环获取任务。获取到的任务为null ，则退出循环。在这个过程中使用**worker对象**的**`lock(）`**和`unlock()`方法进行加锁和解锁，实现操作的线程安全性。在`addworker()方法`中有一个`try`、`catch`、`finally`代码块 `fianlly` 中执行`processWorkerExit()方法`，如果线程是异常终止的话，直接使工作线程数减1即可。如果是正常结束就不用操作，判断线程的状态，判断要不要移除工作线程集合中的这个Worker。
  - **Worker继承于(`AQS`)，实现了Runnable接口，并且内部有一个用`final`修饰的`Thread`类型的变量**
  - Worker之所以要继承 `AQS` 就是为了用上 `lock` 的状态，执行任务的时候上锁，任务执行完了之后解锁，这样执行关闭线程池等操作的时候可以通过 `tryLock` 来判断此时线程是否在干活，如果 `tryLock` 成功说明此时线程是空闲的，可以安全的回收。



## 1、创建线程池的方法

- 使用`Extcutors类`的静态方法获取内置的线程池
- 使用`ThreadPoolExecutor类`的构造函数创建线程池



## 2、使用`ThreadPoolExecutor`构造方法

### 2.1 讲一下`ThreadLocalExecutor`构造器的参数

https://blog.csdn.net/ye17186/article/details/89467919

**总：核心线程数、最大线程数、任务队列、拒绝策略、线程最大闲置时间、时间单位、线程工厂**

- #### **核心线程数**

  线程池中会维护一个最小的线程数量，即使这些线程处理空闲状态，他们也不会被销毁，除非设置了**`allowCoreThreadTimeOut`**。这里的最小线程数量即是**`corePoolSize`**。任务提交到线程池后，首先会检查当前线程数是否达到了**`corePoolSize`**，如果没有达到的话，则会创建一个新线程来处理这个任务。
  ——————————————————————————————————————————————
  
- #### **最大线程数**

  当前线程数达到**`corePoolSize`**后，如果继续有任务被提交到线程池，会将任务缓存到工作队列（后面会介绍）中。如果队列也已满，则会去创建一个新线程来出来这个处理。线程池不会无限制的去创建新线程，它会有一个最大线程数量的限制，这个数量即由**`maxinumPoolSize`**指定

  ——————————————————————————————————————————————

- #### **线程闲置超时时长**

  一个线程如果处于空闲状态，并且当前的线程数量大于**`corePoolSize`**，那么在指定时间后，这个空闲线程会被销毁，这里的指定时间由**`keepAliveTime`**来设定

  ——————————————————————————————————————————————

- #### **时间单位**

  ——————————————————————————————————————————————

- #### **任务队列**

  **当前线程数达到`corePoolSize`后，如果继续有任务被提交到线程池，会将任务缓存到工作队列。**

  > jdk中提供了四种工作队列：
  >
  > - **①`ArrayBlockingQueue`**
  >
  >
  > 基于数组的有界阻塞队列，按`FIFO`排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到`corePoolSize`后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到`maxPoolSize`，则会执行拒绝策略。
  >
  > - ②`LinkedBlockingQuene`
  >
  > 基于链表的无界阻塞队列（其实最大容量为`Interger.MAX`），按照`FIFO`排序。由于该队列的近似无界性，当线程池中线程数量达到`corePoolSize`后，再有新任务进来，会一直存入该队列，而基本不会去创建新线程直到`maxPoolSize`（很难达到`Interger.MAX`这个数），因此使用该工作队列时，参数`maxPoolSize`其实是不起作用的。
  >
  > - **③`SynchronousQuene`**
  >
  > 一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到`maxPoolSize`，则执行拒绝策略。**可能会创建大量线程，从而导致 `OOM`。**
  >
  > - **④`PriorityBlockingQueue`**
  >
  > 具有优先级的无界阻塞队列，优先级通过参数`Comparator`实现

  ——————————————————————————————————————————————

- #### 线程工厂

  **创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等**

  ——————————————————————————————————————————————

  ### 拒绝策略

  **当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，就会触发对应的拒绝策略.**

  > **1）`AbortPolicy`**
  >
  > **`ThreadPoolExecutor.AbortPolicy`**:丢弃任务并抛出**`RejectedExecutionException`**异常。
  >
  > **2）`DiscardPolicy`**
  >
  > **`ThreadPoolExecutor.DiscardPolicy`**：丢弃任务，但是不抛出异常。如果线程队列已满，则后续提交的任务都会被丢弃，且是静默丢弃。
  >
  > **3）`DiscardOldestPolicy`**
  >
  > **`ThreadPoolExecutor.DiscardOldestPolicy`**：丢弃队列最前面的任务，然后重新提交被拒绝的任务。[此策略*将丢弃最早的未处理的任务请求*。]
  >
  > **4）`CallerRunsPolicy`**
  >
  > **`ThreadPoolExecutor.CallerRunsPolicy`**：由调用线程处理该任务

  ——————————————————————————————————————————————

### 2.2 线程池如何动态修改核心线程数和最大线程数？

线程数的设定是一个迭代的过程，需要压测适时调整。

线程池其实已经给予方法暴露出内部的一些状态，例如正在执行的线程数、已完成的任务数、队列中的任务数等等。定时拉取这些数据，然后搞个看板，再结合邮件、短信、钉钉等报警方式，我们可以很容易的监控线程池的状态！



### 2.3 原生线程池的核心线程一定伴随着任务慢慢创建的吗？？如果没有任务了核心线程会怎么处理？

线程池提供了两个方法：

- `prestartCoreThread：`启动一个核心线程
- `prestartAllCoreThreads` ：启动所有核心线程

如果没有使用这两个方法的话

> 原生线程池的核心线程一定伴随着任务慢慢创建的，
>
> **执行一个任务时===执行`addWorker()`**中的**`new worker()`**时创建的。
>
> worker类中有一个用final修饰的Thread变量

有一个参数来标识是否允许核心线程超时的时候被销毁。

#### 2.3.1 核心线程数如何确定

**CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。

**I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

------



### 2.4 sumbit() 和execute()方法的区别

execute()方法中的参数类型Runnable 类型

`sumbit()` 方法中的参数既可以是Runnable 又可以是Callable 类型，并且可以返回一个Future类型的变量



### 2.5、线程池怎么实现任务的优先级调度？

## 3、使用线程池有哪些需要注意的地方？

- 明确指出线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。

- 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。

## 4、ThreadPoolExecutor核心源码分析

**核心属性 ---> 线程池的状态 --->exexcute() 方法**--->addWorker()方法 --->work类--->runWorker()方法--->getTask()--->

![image-20231019152926343](C:\Users\16055\AppData\Roaming\Typora\typora-user-images\image-20231019152926343.png)

- **execute()**

```java
   public void execute(Runnable command) {
       //1、 首先判断executor()方法中传送过来的值是否是null 
         //1.1、如果是null 那就直接返回
        if (command == null)
            throw new NullPointerException();
         //1.2、如果不是null ,那就根据ctl来获取当前线程池中的正在工作的线程数量
        int c = ctl.get();
       	 //1.3、如果工作的线程数 < 核心线程数量 
        if (workerCountOf(c) < corePoolSize) {
            //---> 使用addworker()方法去创建一个核心线程来处理
            if (addWorker(command, true))
                return;
            //---> 如果在并发的情况下，此时刚到临界值，无法再创建核心线程
            c = ctl.get();
        }
       //2、这里是创建核心线程数失败的情况
       		// 判断线程的状态，处于running的话就将任务添加到任务队列当中
        if (isRunning(c) && workQueue.offer(command)) {
            // 但是由于并发问题的存在，可能此时线程池的状态就发生了变化
            int recheck = ctl.get();
            // 重新检查线程池状态，不处于running状态并且将任务移出队列
            if (! isRunning(recheck) && remove(command))
                reject(command);
            // （1处于running 状态或者shutDown状态，并且工作线程数为0）
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
       //3、这里是将任务添加到任务队列当中失败的情况
        else if (!addWorker(command, false))
           //---> 任务添加到工作队列失败，执行拒绝策略
            reject(command);
    }


```

```java
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();
        int rs = runStateOf(c);

        //先判断状态 、
        // Check if queue empty only if necessary.
        	//如果处于SHUTDOWN STOP TIYDING TERMINATED 状态就不可以再接收任务
        if (rs >= SHUTDOWN &&
            // 如果当前处于SHUTDOWN并且工作队列不为空===>此时要创建一个非核心线程来处理
            ! (rs == SHUTDOWN &&
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;
		//再判断数量
        for (;;) {
            
            int wc = workerCountOf(c);
            // 如果超过了最大容量、或者大于核心容量数、或者大于最大线程数，都不能再创建线程
            if (wc >= CAPACITY ||
                wc >= (core ? corePoolSize : maximumPoolSize))
                return false;
            //如果可以创建线程就c++
            if (compareAndIncrementWorkerCount(c))
                break retry;
            c = ctl.get();  // Re-read ctl
            if (runStateOf(c) != rs)
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }

    //创建 Work
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        w = new Worker(firstTask);
        final Thread t = w.thread;
        if (t != null) {
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                // Recheck while holding lock.
                // Back out on ThreadFactory failure or if
                // shut down before lock acquired.
                int rs = runStateOf(ctl.get());

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) {
                    if (t.isAlive()) // precheck that t is startable
                        throw new IllegalThreadStateException();
                    workers.add(w);
                    int s = workers.size();
                    if (s > largestPoolSize)
                        largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted)
            addWorkerFailed(w);
    }
    return workerStarted;
}
```

```java
final void runWorker(Worker w) {
        Thread wt = Thread.currentThread();
        Runnable task = w.firstTask;
        w.firstTask = null;
        w.unlock(); // allow interrupts
        boolean completedAbruptly = true;
        try {
            while (task != null || (task = getTask()) != null) {
                w.lock();
                // If pool is stopping, ensure thread is interrupted;
                // if not, ensure thread is not interrupted.  This
                // requires a recheck in second case to deal with
                // shutdownNow race while clearing interrupt
                if ((runStateAtLeast(ctl.get(), STOP) ||
                     (Thread.interrupted() &&
                      runStateAtLeast(ctl.get(), STOP))) &&
                    !wt.isInterrupted())
                    wt.interrupt();
                try {
                    beforeExecute(wt, task);
                    Throwable thrown = null;
                    try {
                        task.run();
                    } catch (RuntimeException x) {
                        thrown = x; throw x;
                    } catch (Error x) {
                        thrown = x; throw x;
                    } catch (Throwable x) {
                        thrown = x; throw new Error(x);
                    } finally {
                        afterExecute(task, thrown);
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }

```

```java
    private Runnable getTask() {
        boolean timedOut = false; // Did the last poll() time out?

        for (;;) {
            int c = ctl.get();
            int rs = runStateOf(c);

            // Check if queue empty only if necessary.
            if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
                decrementWorkerCount();
                return null;
            }

            int wc = workerCountOf(c);

            // Are workers subject to culling?
            boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

            if ((wc > maximumPoolSize || (timed && timedOut))
                && (wc > 1 || workQueue.isEmpty())) {
                if (compareAndDecrementWorkerCount(c))
                    return null;
                continue;
            }

            try {
                Runnable r = timed ?
                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
                if (r != null)
                    return r;
                timedOut = true;
            } catch (InterruptedException retry) {
                timedOut = false;
            }
        }
    }
```



## 5、线程池里的 `ctl` 是干嘛的咯？

`ctl`是线程池中一个**`AtomicInteger类型`**的变量，它的高3位表示线程池所处的状态，低29位表示线程池中工作线程的数量。在线程池运行的过程中，通过`ctl参数`的值来判断线程池所处的状态



## 6、线程池的状态？

- RUNNING：能接受新任务，并处理阻塞队列中的任务 （-1）
- SHUTDOWN：不接受新任务，但是可以处理阻塞队列中的任务
- STOP：不接受新任务，并且不处理阻塞队列中的任务，并且还打断正在运行任务的线程，就是直接撂担子不干了！
- TIDYING：所有任务都终止，并且工作线程也为0，处于关闭之前的状态
- TERMINATED：已关闭。

#  

 ![图解线程池实现原理](https://oss.javaguide.cn/javaguide/图解线程池实现原理.png)

 





# 问题 

## 1、如果线程池中的线程在执行任务的时候，抛异常了，会怎么样？

`task.run()` 被 `try catch finally`包裹，异常被扔到了 `afterExecute` 中，并且也继续被抛了出来。最终会执行 `processWorkerExit方法`,这个方法的处理逻辑是把这个线程废了，然后新建一个线程替换之。

所以如果一个任务执行一半就抛出异常，并且你没有自行处理这个异常，那么这个任务就这样戛然而止了，后面也不会有线程继续执行剩下的逻辑。



如果使用的是线程池的submit()方法，那么异常会被FutureTask捕获。

### 2、[线程池](https://so.csdn.net/so/search?q=线程池&spm=1001.2101.3001.7020)中某个线程出现异常，它是否会影响线程池中的其它线程？

 答案是不会，不会影响线程池里面其他线程的正常执行，可以自行验证。

### 3、出现异常的该线程何去何从？用完之后是否会重新进入线程池

如果使用的是线程池的executor()方法，那么会直接抛出异常。

如果使用的是线程池的submit()方法，那么异常会被FutureTask捕获。

在线程池内部在执行run()方法的时候会通过catch来捕获异常，让run方法正常执行，run方法执行完之后，

 答案是不会重新进入线程池，线程池会把这个线程移除掉，并创建一个新的线程放到线程池中。

### 4、如果线程池中的线程数量已经到达 maximumPoolSize，但是仍然有新任务来临，并且该任务的优先级比较高，不允许直接丢弃，希望该任务立即执行，该如何处理



7、原子类